{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Load & preprocess\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "x_train = (x_train.astype(\"float32\") / 255.0)  \n",
    "x_test  = (x_test.astype(\"float32\")  / 255.0) \n",
    "\n",
    "class_names = [\n",
    "    \"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\n",
    "    \"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([\n",
    "    layers.Input(shape=(28, 28)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "#     layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential\n",
    "model=Sequential([\n",
    "    layers.Input(shape=(28, 28)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(50, activation=\"relu\"),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(50, activation=\"relu\"),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(50, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\"),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functional\n",
    "inputs = tf.keras.Input(shape=(28, 28), name=\"image\")\n",
    "x = layers.Flatten(name=\"flatten\")(inputs)\n",
    "x = layers.Dense(256, activation=\"relu\", name=\"dense_1\")(x)\n",
    "x = layers.Dropout(0.3, name=\"dropout_1\")(x)\n",
    "x = layers.Dense(128, activation=\"relu\", name=\"dense_2\")(x)\n",
    "x = layers.Dropout(0.2, name=\"dropout_2\")(x)\n",
    "\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "# price = layers.Dense(1, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs, name=\"fashion_mnist_mlp\")\n",
    "# modelp =  Model(inputs=inputs, outputs=price, name=\"fashion_mnist_mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fashion_mnist_mlp\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image (InputLayer)           [(None, 28, 28)]          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "422/422 - 3s - loss: 0.6108 - accuracy: 0.7804 - val_loss: 0.4053 - val_accuracy: 0.8508\n",
      "Epoch 2/50\n",
      "422/422 - 2s - loss: 0.4308 - accuracy: 0.8448 - val_loss: 0.3610 - val_accuracy: 0.8645\n",
      "Epoch 3/50\n",
      "422/422 - 4s - loss: 0.3900 - accuracy: 0.8569 - val_loss: 0.3681 - val_accuracy: 0.8647\n",
      "Epoch 4/50\n",
      "422/422 - 4s - loss: 0.3654 - accuracy: 0.8661 - val_loss: 0.3483 - val_accuracy: 0.8717\n",
      "Epoch 5/50\n",
      "422/422 - 2s - loss: 0.3526 - accuracy: 0.8711 - val_loss: 0.3405 - val_accuracy: 0.8735\n",
      "Epoch 6/50\n",
      "422/422 - 2s - loss: 0.3371 - accuracy: 0.8756 - val_loss: 0.3412 - val_accuracy: 0.8805\n",
      "Epoch 7/50\n",
      "422/422 - 2s - loss: 0.3230 - accuracy: 0.8811 - val_loss: 0.3370 - val_accuracy: 0.8733\n",
      "Epoch 8/50\n",
      "422/422 - 2s - loss: 0.3152 - accuracy: 0.8831 - val_loss: 0.3203 - val_accuracy: 0.8820\n",
      "Epoch 9/50\n",
      "422/422 - 2s - loss: 0.3073 - accuracy: 0.8865 - val_loss: 0.3201 - val_accuracy: 0.8848\n",
      "Epoch 10/50\n",
      "422/422 - 2s - loss: 0.3000 - accuracy: 0.8892 - val_loss: 0.3145 - val_accuracy: 0.8925\n",
      "Epoch 11/50\n",
      "422/422 - 2s - loss: 0.2926 - accuracy: 0.8911 - val_loss: 0.3139 - val_accuracy: 0.8862\n",
      "Epoch 12/50\n",
      "422/422 - 2s - loss: 0.2848 - accuracy: 0.8926 - val_loss: 0.3125 - val_accuracy: 0.8867\n",
      "Epoch 13/50\n",
      "422/422 - 2s - loss: 0.2823 - accuracy: 0.8939 - val_loss: 0.3167 - val_accuracy: 0.8815\n",
      "Epoch 14/50\n",
      "422/422 - 2s - loss: 0.2761 - accuracy: 0.8973 - val_loss: 0.3132 - val_accuracy: 0.8903\n",
      "Epoch 15/50\n",
      "422/422 - 2s - loss: 0.2735 - accuracy: 0.8971 - val_loss: 0.3096 - val_accuracy: 0.8847\n",
      "Epoch 16/50\n",
      "422/422 - 2s - loss: 0.2674 - accuracy: 0.8998 - val_loss: 0.2987 - val_accuracy: 0.8915\n",
      "Epoch 17/50\n",
      "422/422 - 2s - loss: 0.2606 - accuracy: 0.9010 - val_loss: 0.3025 - val_accuracy: 0.8973\n",
      "Epoch 18/50\n",
      "422/422 - 2s - loss: 0.2589 - accuracy: 0.9026 - val_loss: 0.3032 - val_accuracy: 0.8943\n",
      "Epoch 19/50\n",
      "422/422 - 2s - loss: 0.2560 - accuracy: 0.9046 - val_loss: 0.3050 - val_accuracy: 0.8937\n",
      "Epoch 20/50\n",
      "422/422 - 2s - loss: 0.2481 - accuracy: 0.9066 - val_loss: 0.3089 - val_accuracy: 0.8875\n",
      "Epoch 21/50\n",
      "422/422 - 2s - loss: 0.2465 - accuracy: 0.9066 - val_loss: 0.2952 - val_accuracy: 0.8957\n",
      "Epoch 22/50\n",
      "422/422 - 2s - loss: 0.2432 - accuracy: 0.9084 - val_loss: 0.3017 - val_accuracy: 0.8952\n",
      "Epoch 23/50\n",
      "422/422 - 2s - loss: 0.2392 - accuracy: 0.9106 - val_loss: 0.2943 - val_accuracy: 0.8953\n",
      "Epoch 24/50\n",
      "422/422 - 2s - loss: 0.2388 - accuracy: 0.9107 - val_loss: 0.3134 - val_accuracy: 0.8918\n",
      "Epoch 25/50\n",
      "422/422 - 2s - loss: 0.2343 - accuracy: 0.9117 - val_loss: 0.2977 - val_accuracy: 0.8943\n",
      "Epoch 26/50\n",
      "422/422 - 2s - loss: 0.2328 - accuracy: 0.9120 - val_loss: 0.3022 - val_accuracy: 0.8972\n",
      "Epoch 27/50\n",
      "422/422 - 2s - loss: 0.2272 - accuracy: 0.9145 - val_loss: 0.3048 - val_accuracy: 0.8913\n",
      "Epoch 28/50\n",
      "422/422 - 2s - loss: 0.2285 - accuracy: 0.9134 - val_loss: 0.2981 - val_accuracy: 0.8955\n",
      "Epoch 29/50\n",
      "422/422 - 2s - loss: 0.2224 - accuracy: 0.9146 - val_loss: 0.3037 - val_accuracy: 0.8953\n",
      "Epoch 30/50\n",
      "422/422 - 2s - loss: 0.2215 - accuracy: 0.9162 - val_loss: 0.3027 - val_accuracy: 0.8973\n",
      "Epoch 31/50\n",
      "422/422 - 2s - loss: 0.2203 - accuracy: 0.9171 - val_loss: 0.3060 - val_accuracy: 0.8932\n",
      "Epoch 32/50\n",
      "422/422 - 2s - loss: 0.2153 - accuracy: 0.9186 - val_loss: 0.2956 - val_accuracy: 0.8948\n",
      "Epoch 33/50\n",
      "422/422 - 2s - loss: 0.2148 - accuracy: 0.9190 - val_loss: 0.3014 - val_accuracy: 0.8978\n",
      "Epoch 34/50\n",
      "422/422 - 2s - loss: 0.2112 - accuracy: 0.9189 - val_loss: 0.3162 - val_accuracy: 0.8973\n",
      "Epoch 35/50\n",
      "422/422 - 2s - loss: 0.2087 - accuracy: 0.9206 - val_loss: 0.2976 - val_accuracy: 0.8962\n",
      "Epoch 36/50\n",
      "422/422 - 2s - loss: 0.2056 - accuracy: 0.9212 - val_loss: 0.3120 - val_accuracy: 0.8940\n",
      "Epoch 37/50\n",
      "422/422 - 2s - loss: 0.2080 - accuracy: 0.9195 - val_loss: 0.3146 - val_accuracy: 0.8927\n",
      "Epoch 38/50\n",
      "422/422 - 2s - loss: 0.2031 - accuracy: 0.9224 - val_loss: 0.3167 - val_accuracy: 0.8945\n",
      "Epoch 39/50\n",
      "422/422 - 2s - loss: 0.2030 - accuracy: 0.9216 - val_loss: 0.2963 - val_accuracy: 0.8988\n",
      "Epoch 40/50\n",
      "422/422 - 2s - loss: 0.1995 - accuracy: 0.9244 - val_loss: 0.3147 - val_accuracy: 0.8972\n",
      "Epoch 41/50\n",
      "422/422 - 2s - loss: 0.1964 - accuracy: 0.9245 - val_loss: 0.3190 - val_accuracy: 0.8958\n",
      "Epoch 42/50\n",
      "422/422 - 2s - loss: 0.1971 - accuracy: 0.9246 - val_loss: 0.3104 - val_accuracy: 0.8973\n",
      "Epoch 43/50\n",
      "422/422 - 2s - loss: 0.1938 - accuracy: 0.9256 - val_loss: 0.3153 - val_accuracy: 0.8963\n",
      "Epoch 44/50\n",
      "422/422 - 2s - loss: 0.1945 - accuracy: 0.9255 - val_loss: 0.3009 - val_accuracy: 0.8953\n",
      "Epoch 45/50\n",
      "422/422 - 2s - loss: 0.1928 - accuracy: 0.9263 - val_loss: 0.3056 - val_accuracy: 0.8978\n",
      "Epoch 46/50\n",
      "422/422 - 2s - loss: 0.1898 - accuracy: 0.9280 - val_loss: 0.3173 - val_accuracy: 0.8970\n",
      "Epoch 47/50\n",
      "422/422 - 2s - loss: 0.1918 - accuracy: 0.9274 - val_loss: 0.3304 - val_accuracy: 0.8988\n",
      "Epoch 48/50\n",
      "422/422 - 2s - loss: 0.1864 - accuracy: 0.9292 - val_loss: 0.3047 - val_accuracy: 0.8997\n",
      "Epoch 49/50\n",
      "422/422 - 2s - loss: 0.1829 - accuracy: 0.9300 - val_loss: 0.3214 - val_accuracy: 0.8983\n",
      "Epoch 50/50\n",
      "422/422 - 2s - loss: 0.1850 - accuracy: 0.9299 - val_loss: 0.3097 - val_accuracy: 0.8987\n"
     ]
    }
   ],
   "source": [
    "# 3) Train (with EarlyStopping)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=3, restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_split=0.1,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "#     callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 0.8966 | Test loss: 0.3263\n",
      "\n",
      "Sample predictions:\n",
      "Image 0: predicted=Ankle boot (class 9), true=Ankle boot\n",
      "Image 1: predicted=Pullover (class 2), true=Pullover\n",
      "Image 2: predicted=Trouser (class 1), true=Trouser\n",
      "Image 3: predicted=Trouser (class 1), true=Trouser\n",
      "Image 4: predicted=Shirt (class 6), true=Shirt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4) Evaluate\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"\\nTest accuracy: {test_acc:.4f} | Test loss: {test_loss:.4f}\")\n",
    "\n",
    "# 5) Quick predictions demo (first 5 test images)\n",
    "probs = model.predict(x_test[:5])\n",
    "preds = probs.argmax(axis=1)\n",
    "print(\"\\nSample predictions:\")\n",
    "for i, p in enumerate(preds):\n",
    "    print(f\"Image {i}: predicted={class_names[p]} (class {p}), true={class_names[y_test[i]]}\")\n",
    "\n",
    "# 6) (Optional) Save the model\n",
    "# model.save(\"fashion_mnist_sequential_cnn.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"california_housing_regressor\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "features (InputLayer)        [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               1152      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "median_house_value (Dense)   (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 12,289\n",
      "Trainable params: 11,905\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "52/52 [==============================] - 1s 7ms/step - loss: 1.0675 - mae: 0.7629 - val_loss: 1.6611 - val_mae: 1.0039\n",
      "Epoch 2/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5378 - mae: 0.5407 - val_loss: 1.1303 - val_mae: 0.7320\n",
      "Epoch 3/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4907 - mae: 0.5131 - val_loss: 0.8255 - val_mae: 0.5637\n",
      "Epoch 4/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4535 - mae: 0.4906 - val_loss: 1.0501 - val_mae: 0.4938\n",
      "Epoch 5/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4375 - mae: 0.4759 - val_loss: 1.1861 - val_mae: 0.4680\n",
      "Epoch 6/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4161 - mae: 0.4671 - val_loss: 0.8512 - val_mae: 0.4583\n",
      "Epoch 7/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4106 - mae: 0.4599 - val_loss: 0.6718 - val_mae: 0.4335\n",
      "Epoch 8/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3937 - mae: 0.4521 - val_loss: 0.5691 - val_mae: 0.4355\n",
      "Epoch 9/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3873 - mae: 0.4463 - val_loss: 0.4484 - val_mae: 0.4249\n",
      "Epoch 10/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3759 - mae: 0.4397 - val_loss: 0.4567 - val_mae: 0.4361\n",
      "Epoch 11/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3685 - mae: 0.4354 - val_loss: 0.5652 - val_mae: 0.4204\n",
      "Epoch 12/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3568 - mae: 0.4265 - val_loss: 0.4368 - val_mae: 0.4138\n",
      "Epoch 13/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3501 - mae: 0.4220 - val_loss: 0.4399 - val_mae: 0.4122\n",
      "Epoch 14/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3410 - mae: 0.4162 - val_loss: 0.4968 - val_mae: 0.4112\n",
      "Epoch 15/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3364 - mae: 0.4115 - val_loss: 0.5507 - val_mae: 0.4105\n",
      "Epoch 16/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3327 - mae: 0.4090 - val_loss: 0.4329 - val_mae: 0.4064\n",
      "Epoch 17/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3252 - mae: 0.4043 - val_loss: 0.4166 - val_mae: 0.3983\n",
      "Epoch 18/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3208 - mae: 0.4004 - val_loss: 0.4132 - val_mae: 0.3994\n",
      "Epoch 19/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3206 - mae: 0.4005 - val_loss: 0.4430 - val_mae: 0.4077\n",
      "Epoch 20/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3175 - mae: 0.3990 - val_loss: 0.3905 - val_mae: 0.3977\n",
      "Epoch 21/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3163 - mae: 0.3984 - val_loss: 0.4076 - val_mae: 0.3992\n",
      "Epoch 22/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3144 - mae: 0.3950 - val_loss: 0.3731 - val_mae: 0.3948\n",
      "Epoch 23/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3095 - mae: 0.3925 - val_loss: 0.4383 - val_mae: 0.4001\n",
      "Epoch 24/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3063 - mae: 0.3901 - val_loss: 0.3856 - val_mae: 0.3937\n",
      "Epoch 25/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3039 - mae: 0.3894 - val_loss: 0.3647 - val_mae: 0.3927\n",
      "Epoch 26/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3001 - mae: 0.3856 - val_loss: 0.3430 - val_mae: 0.3931\n",
      "Epoch 27/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3003 - mae: 0.3860 - val_loss: 0.3290 - val_mae: 0.3867\n",
      "Epoch 28/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2951 - mae: 0.3844 - val_loss: 0.3119 - val_mae: 0.3876\n",
      "Epoch 29/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2991 - mae: 0.3846 - val_loss: 0.3211 - val_mae: 0.3857\n",
      "Epoch 30/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2941 - mae: 0.3813 - val_loss: 0.3669 - val_mae: 0.3856\n",
      "Epoch 31/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2943 - mae: 0.3817 - val_loss: 0.3633 - val_mae: 0.3881\n",
      "Epoch 32/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2953 - mae: 0.3816 - val_loss: 0.4311 - val_mae: 0.3920\n",
      "Epoch 33/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2945 - mae: 0.3795 - val_loss: 0.4384 - val_mae: 0.3898\n",
      "Epoch 34/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2844 - mae: 0.3727 - val_loss: 0.4090 - val_mae: 0.3831\n",
      "Epoch 35/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2863 - mae: 0.3749 - val_loss: 0.3949 - val_mae: 0.3886\n",
      "Epoch 36/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2853 - mae: 0.3746 - val_loss: 0.3834 - val_mae: 0.3815\n",
      "Epoch 37/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2863 - mae: 0.3750 - val_loss: 0.3555 - val_mae: 0.3792\n",
      "Epoch 38/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2823 - mae: 0.3731 - val_loss: 0.3308 - val_mae: 0.3793\n",
      "Epoch 39/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2812 - mae: 0.3704 - val_loss: 0.3306 - val_mae: 0.3822\n",
      "Epoch 40/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2795 - mae: 0.3687 - val_loss: 0.3274 - val_mae: 0.3780\n",
      "Epoch 41/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2830 - mae: 0.3716 - val_loss: 0.3357 - val_mae: 0.3794\n",
      "Epoch 42/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2790 - mae: 0.3696 - val_loss: 0.3305 - val_mae: 0.3844\n",
      "Epoch 43/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2830 - mae: 0.3727 - val_loss: 0.3276 - val_mae: 0.3835\n",
      "Epoch 44/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2819 - mae: 0.3728 - val_loss: 0.3234 - val_mae: 0.3799\n",
      "Epoch 45/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2793 - mae: 0.3694 - val_loss: 0.3208 - val_mae: 0.3809\n",
      "Epoch 46/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2834 - mae: 0.3715 - val_loss: 0.3246 - val_mae: 0.3805\n",
      "Epoch 47/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2753 - mae: 0.3674 - val_loss: 0.3213 - val_mae: 0.3786\n",
      "Epoch 48/200\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.2774 - mae: 0.3677 - val_loss: 0.3187 - val_mae: 0.3804\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# California Housing — Neural Network Regressor (Keras Functional API)\n",
    "# ---------------------------------------------------------------\n",
    "# Requirements: tensorflow>=2.9, scikit-learn, matplotlib (optional for plot)\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# ---------- Reproducibility ----------\n",
    "# SEED = 42\n",
    "# random.seed(SEED)\n",
    "# np.random.seed(SEED)\n",
    "# tf.keras.utils.set_random_seed(SEED)\n",
    "\n",
    "# ---------- Load data ----------\n",
    "# y is the median house value in units of $100,000 (original dataset definition)\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "\n",
    "# Train/val/test split: 64% train, 16% val, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=SEED\n",
    ")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.20, random_state=SEED\n",
    ")\n",
    "\n",
    "# ---------- Scale features ----------\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s   = scaler.transform(X_val)\n",
    "X_test_s  = scaler.transform(X_test)\n",
    "\n",
    "n_features = X_train_s.shape[1]\n",
    "\n",
    "# ---------- Build model (Functional API) ----------\n",
    "def build_model(n_features: int) -> tf.keras.Model:\n",
    "    inputs = tf.keras.Input(shape=(n_features,), name=\"features\")\n",
    "    x = tf.keras.layers.Dense(128, activation=\"relu\", kernel_initializer=\"he_normal\")(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.10)(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(64, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)\n",
    "    outputs = tf.keras.layers.Dense(1, name=\"median_house_value\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"california_housing_regressor\")\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"mse\",                                # optimize MSE\n",
    "        metrics=[tf.keras.metrics.MeanAbsoluteError(name=\"mae\")]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = build_model(n_features)\n",
    "model.summary()\n",
    "\n",
    "# ---------- Training ----------\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=20,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_s, y_train,\n",
    "    validation_data=(X_val_s, y_val),\n",
    "    epochs=200,\n",
    "    batch_size=256,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ---------- Evaluate ----------\n",
    "y_pred = model.predict(X_test_s).ravel()\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nTest RMSE: {rmse:.4f}\")\n",
    "print(f\"Test MAE : {mae:.4f}\")\n",
    "print(f\"Test R^2 : {r2:.4f}\")\n",
    "\n",
    "# ---------- Plot training curves ----------\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------- (Optional) Save model & scaler ----------\n",
    "# model.save(\"california_housing_regressor.keras\")\n",
    "# import joblib; joblib.dump(scaler, \"scaler.joblib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
